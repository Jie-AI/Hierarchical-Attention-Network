{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"They think he's a good president because he's done things they like: appointing conservatives to the court and cutting taxes, for example. But every other normal Republican would have done the exact same things, made actual deals to get much more, and they'd have left out all the ridiculous drama that keeps Trump's approval so low and his accomplishments so meager.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns = [\"sentence\"])\n",
    "\n",
    "df[\"sentence\"] = sentences\n",
    "df[\"sentence\"] = df.sentence.map(lambda s :  s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words'] = df.sentence.map(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [they, think, he, 's, a, good, president, beca...\n",
       "1    [but, every, other, normal, republican, would,...\n",
       "Name: words, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_len = df.words.map(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "vocab = list(set(itertools.chain.from_iterable(df.words.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accomplishments',\n",
       " 'done',\n",
       " 'his',\n",
       " 'a',\n",
       " 'like',\n",
       " ',',\n",
       " 'they',\n",
       " 'same',\n",
       " 'cutting',\n",
       " 'deals',\n",
       " 'keeps',\n",
       " 'appointing',\n",
       " 'and',\n",
       " 'but',\n",
       " 'actual',\n",
       " 'that',\n",
       " 'conservatives',\n",
       " 'out',\n",
       " 'low',\n",
       " 'the',\n",
       " 'republican',\n",
       " 'every',\n",
       " 'meager',\n",
       " 'example',\n",
       " 'exact',\n",
       " 'get',\n",
       " 'to',\n",
       " \"'d\",\n",
       " 'all',\n",
       " 'because',\n",
       " 'made',\n",
       " 'drama',\n",
       " ':',\n",
       " 'he',\n",
       " 'things',\n",
       " 'normal',\n",
       " 'left',\n",
       " '.',\n",
       " \"'s\",\n",
       " 'other',\n",
       " 'president',\n",
       " 'ridiculous',\n",
       " 'trump',\n",
       " 'good',\n",
       " 'would',\n",
       " 'court',\n",
       " 'approval',\n",
       " 'for',\n",
       " 'think',\n",
       " 'have',\n",
       " 'more',\n",
       " 'so',\n",
       " 'taxes',\n",
       " 'much']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "?re.match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 4), match='done'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(\"\\w+\",vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matcher(word):\n",
    "    return re.match(\"\\w+\", word)\n",
    "\n",
    "vocab = list(filter(matcher, itertools.chain.from_iterable(df.words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab += [\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they',\n",
       " 'think',\n",
       " 'he',\n",
       " 'a',\n",
       " 'good',\n",
       " 'president',\n",
       " 'because',\n",
       " 'he',\n",
       " 'done',\n",
       " 'things',\n",
       " 'they',\n",
       " 'like',\n",
       " 'appointing',\n",
       " 'conservatives',\n",
       " 'to',\n",
       " 'the',\n",
       " 'court',\n",
       " 'and',\n",
       " 'cutting',\n",
       " 'taxes',\n",
       " 'for',\n",
       " 'example',\n",
       " 'but',\n",
       " 'every',\n",
       " 'other',\n",
       " 'normal',\n",
       " 'republican',\n",
       " 'would',\n",
       " 'have',\n",
       " 'done',\n",
       " 'the',\n",
       " 'exact',\n",
       " 'same',\n",
       " 'things',\n",
       " 'made',\n",
       " 'actual',\n",
       " 'deals',\n",
       " 'to',\n",
       " 'get',\n",
       " 'much',\n",
       " 'more',\n",
       " 'and',\n",
       " 'they',\n",
       " 'have',\n",
       " 'left',\n",
       " 'out',\n",
       " 'all',\n",
       " 'the',\n",
       " 'ridiculous',\n",
       " 'drama',\n",
       " 'that',\n",
       " 'keeps',\n",
       " 'trump',\n",
       " 'approval',\n",
       " 'so',\n",
       " 'low',\n",
       " 'and',\n",
       " 'his',\n",
       " 'accomplishments',\n",
       " 'so',\n",
       " 'meager',\n",
       " '<unk>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2vocab = {\n",
    "    index: word\n",
    "    for index, word in enumerate(vocab)\n",
    "}\n",
    "\n",
    "vocab2index = {\n",
    "    word: index\n",
    "    for index, word in enumerate(vocab)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'they': 42,\n",
       " 'think': 1,\n",
       " 'he': 7,\n",
       " 'a': 3,\n",
       " 'good': 4,\n",
       " 'president': 5,\n",
       " 'because': 6,\n",
       " 'done': 29,\n",
       " 'things': 33,\n",
       " 'like': 11,\n",
       " 'appointing': 12,\n",
       " 'conservatives': 13,\n",
       " 'to': 37,\n",
       " 'the': 47,\n",
       " 'court': 16,\n",
       " 'and': 56,\n",
       " 'cutting': 18,\n",
       " 'taxes': 19,\n",
       " 'for': 20,\n",
       " 'example': 21,\n",
       " 'but': 22,\n",
       " 'every': 23,\n",
       " 'other': 24,\n",
       " 'normal': 25,\n",
       " 'republican': 26,\n",
       " 'would': 27,\n",
       " 'have': 43,\n",
       " 'exact': 31,\n",
       " 'same': 32,\n",
       " 'made': 34,\n",
       " 'actual': 35,\n",
       " 'deals': 36,\n",
       " 'get': 38,\n",
       " 'much': 39,\n",
       " 'more': 40,\n",
       " 'left': 44,\n",
       " 'out': 45,\n",
       " 'all': 46,\n",
       " 'ridiculous': 48,\n",
       " 'drama': 49,\n",
       " 'that': 50,\n",
       " 'keeps': 51,\n",
       " 'trump': 52,\n",
       " 'approval': 53,\n",
       " 'so': 59,\n",
       " 'low': 55,\n",
       " 'his': 57,\n",
       " 'accomplishments': 58,\n",
       " 'meager': 60,\n",
       " '<unk>': 61}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_index(word):\n",
    "    index = vocab2index.get(\n",
    "        word,\n",
    "        vocab2index[\"<unk>\"]\n",
    "    )\n",
    "    return index\n",
    "\n",
    "df[\"word_indices\"] = df.words.map(\n",
    "    lambda words: list(map(get_word_index, words))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [42, 1, 7, 61, 3, 4, 5, 6, 7, 61, 29, 33, 42, ...\n",
       "1    [22, 23, 24, 25, 26, 27, 43, 29, 47, 31, 32, 3...\n",
       "Name: word_indices, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 1, 7, 61, 3, 4, 5, 6, 7, 61, 29, 33, 42, 11, 61, 12, 13, 37, 47, 16, 56, 18, 19, 61, 20, 21, 61]\n",
      "[22, 23, 24, 25, 26, 27, 43, 29, 47, 31, 32, 33, 61, 34, 35, 36, 37, 38, 39, 40, 61, 56, 42, 61, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 61, 53, 59, 55, 56, 57, 58, 59, 60, 61]\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def list2var(l):\n",
    "    print(l)\n",
    "    tensor = torch.LongTensor(l)\n",
    "    return Variable(tensor)\n",
    "\n",
    "variables = df.word_indices.map(list2var).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "seq = pad_sequence(variables, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(num_embeddings=len(vocab), embedding_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = embedding(seq[0])\n",
    "b = embedding(seq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 44, 100])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.stack([a,b], dim=0)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42,  1,  7, 61,  3,  4,  5,  6,  7, 61, 29, 33, 42, 11, 61, 12, 13, 37,\n",
       "         47, 16, 56, 18, 19, 61, 20, 21, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [22, 23, 24, 25, 26, 27, 43, 29, 47, 31, 32, 33, 61, 34, 35, 36, 37, 38,\n",
       "         39, 40, 61, 56, 42, 61, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 61, 53,\n",
       "         59, 55, 56, 57, 58, 59, 60, 61]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 44])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "\n",
    "gru = WordGRU(100, len(vocab), bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'lengths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-4a5ac8e68f24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mh_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'lengths'"
     ]
    }
   ],
   "source": [
    "h_0 = torch.zeros(2, 2, 100)\n",
    "o, h = gru(seq)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 sentences\n",
    "- 44 words in each\n",
    "- 100 dim of each word\n",
    "- PyTorch LSTM is only concerned with the last dimension (100)\n",
    "- For word attention all sentences( each sentence is a batch ) is padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = WordAttention(200)\n",
    "s_vec = attn(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 Sentences\n",
    "- Each sentence of size 200\n",
    "- A batch of documents would have shape: `[batch_size, max_sent_len, max_word_len]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_gru = SentenceGRU(200, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_vec.unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_0_s = torch.zeros(2,1,100)\n",
    "sentence_output, h_s = sentence_gru(s_vec.unsqueeze(dim=0), h_0_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_attn = SentenceAttention(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vec = s_attn(sentence_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = OutputLayer(200,2)\n",
    "output = output_layer(d_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.squeeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = loss(output, torch.LongTensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things that the HAN module should do:\n",
    "   Take in a batch of documents -> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out a complete HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word_gru = WordGRU(50, 6, 2, 50)\n",
    "test_word_attn = WordAttention(100)\n",
    "\n",
    "words = []\n",
    "sentence_vec = []\n",
    "for document in documents:\n",
    "    encoded_words, encoded_hidden = test_word_gru(document)\n",
    "    words.append(encoded_words)\n",
    "    encoded_sentence = test_word_attn(encoded_words) \n",
    "    sentence_vec.append(encoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tensor = torch.stack(sentence_vec, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent_gru = SentenceGRU(100, 50 )\n",
    "encoded_sentence, sentence_hidden = test_sent_gru(doc_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent_attn = SentenceAttention(100)\n",
    "encoded_doc = test_sent_attn(encoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vec[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentence_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import HAN\n",
    "\n",
    "han = HAN(\n",
    "    vocab_size=6,\n",
    "    embedding_dim=50,\n",
    "    word_hidden_size=50,\n",
    "    sent_hidden_size=50,\n",
    "    num_labels=2,\n",
    "    bidirectional=True,\n",
    "    cuda=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordGRU(\n",
       "  (embedding): Embedding(6, 50)\n",
       "  (gru): GRU(50, 50, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "han.word_gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordAttention(\n",
       "  (linear): Linear(in_features=100, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "han.word_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = torch.LongTensor(\n",
    "[\n",
    "    [\n",
    "        [\n",
    "            1,2,3,4,5\n",
    "        ], # sent 1\n",
    "        [\n",
    "            1,2,3,0,0\n",
    "            \n",
    "        ], # sent 2\n",
    "    ], #Doc 1\n",
    "    [\n",
    "        [1,2,3,4,5],\n",
    "        [1,2,3,4,5]\n",
    "    ], #Doc 2\n",
    "    [\n",
    "        [1,2,3,4,5],\n",
    "        [0,0,0,0,0]\n",
    "    ] #Doc 3\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3 Documents\n",
    "- A Max of 2 sentences \n",
    "- Max of 5 words in each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of input to WordGRU  torch.Size([2, 5])\n",
      "Dimension of output from WordGRU  torch.Size([2, 5, 100])\n",
      "Dimension of input to WordAttn torch.Size([2, 5, 100])\n",
      "Dimension of input to WordGRU  torch.Size([2, 5])\n",
      "Dimension of output from WordGRU  torch.Size([2, 5, 100])\n",
      "Dimension of input to WordAttn torch.Size([2, 5, 100])\n",
      "Dimension of input to WordGRU  torch.Size([2, 5])\n",
      "Dimension of output from WordGRU  torch.Size([2, 5, 100])\n",
      "Dimension of input to WordAttn torch.Size([2, 5, 100])\n",
      "Size of Doc Vector  torch.Size([3, 2, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shikhar/Documents/HAN/models.py:181: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  o = self.softmax(o)\n"
     ]
    }
   ],
   "source": [
    "o = han(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4218, -1.0667],\n",
       "        [-0.6086, -0.7856],\n",
       "        [-0.3362, -1.2536]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randint() received an invalid combination of arguments - got (int, int, tuple, dtype=torch.tensortype), but expected one of:\n * (int high, tuple of ints size, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool requires_grad)\n * (int high, tuple of ints size, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool requires_grad)\n * (int low, int high, tuple of ints size, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool requires_grad)\n * (int low, int high, tuple of ints size, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-825fb08f0677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: randint() received an invalid combination of arguments - got (int, int, tuple, dtype=torch.tensortype), but expected one of:\n * (int high, tuple of ints size, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool requires_grad)\n * (int high, tuple of ints size, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool requires_grad)\n * (int low, int high, tuple of ints size, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool requires_grad)\n * (int low, int high, tuple of ints size, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "documents = torch.randint(0,99, (3,20,100), dtype=torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "_th_uniform_ is not implemented for type torch.LongTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-18522ff2b7b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: _th_uniform_ is not implemented for type torch.LongTensor"
     ]
    }
   ],
   "source": [
    "d = torch.rand_like(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.randint(0,5, (10,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.view(10,20,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of input to WordGRU  torch.Size([20, 5])\n",
      "Dimension of output from WordGRU  torch.Size([20, 5, 100])\n",
      "Dimension of input to WordAttn torch.Size([20, 5, 100])\n",
      "Dimension of input to WordGRU  torch.Size([20, 5])\n",
      "Dimension of output from WordGRU  torch.Size([20, 5, 100])\n",
      "Dimension of input to WordAttn torch.Size([20, 5, 100])\n",
      "Dimension of input to WordGRU  torch.Size([20, 5])\n",
      "Dimension of output from WordGRU  torch.Size([20, 5, 100])\n",
      "Dimension of input to WordAttn torch.Size([20, 5, 100])\n",
      "Dimension of input to WordGRU  torch.Size([20, 5])\n",
      "Dimension of output from WordGRU  torch.Size([20, 5, 100])\n",
      "Dimension of input to WordAttn torch.Size([20, 5, 100])\n",
      "Dimension of input to WordGRU  torch.Size([20, 5])\n",
      "Dimension of output from WordGRU  torch.Size([20, 5, 100])\n",
      "Dimension of input to WordAttn torch.Size([20, 5, 100])\n",
      "Dimension of input to WordGRU  torch.Size([20, 5])\n",
      "Dimension of output from WordGRU  torch.Size([20, 5, 100])\n",
      "Dimension of input to WordAttn torch.Size([20, 5, 100])\n",
      "Dimension of input to WordGRU  torch.Size([20, 5])\n",
      "Dimension of output from WordGRU  torch.Size([20, 5, 100])\n",
      "Dimension of input to WordAttn torch.Size([20, 5, 100])\n",
      "Dimension of input to WordGRU  torch.Size([20, 5])\n",
      "Dimension of output from WordGRU  torch.Size([20, 5, 100])\n",
      "Dimension of input to WordAttn torch.Size([20, 5, 100])\n",
      "Dimension of input to WordGRU  torch.Size([20, 5])\n",
      "Dimension of output from WordGRU  torch.Size([20, 5, 100])\n",
      "Dimension of input to WordAttn torch.Size([20, 5, 100])\n",
      "Dimension of input to WordGRU  torch.Size([20, 5])\n",
      "Dimension of output from WordGRU  torch.Size([20, 5, 100])\n",
      "Dimension of input to WordAttn torch.Size([20, 5, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shikhar/Documents/HAN/models.py:188: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  o = self.softmax(o)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-3.1366e-03, -5.7662e+00],\n",
       "        [-2.1672e+00, -1.2161e-01],\n",
       "        [-3.5557e+00, -2.8976e-02],\n",
       "        [-1.0627e+01, -2.3842e-05],\n",
       "        [-1.4499e+00, -2.6735e-01],\n",
       "        [-1.3893e-02, -4.2833e+00],\n",
       "        [-3.0451e-03, -5.7956e+00],\n",
       "        [-3.2339e+00, -4.0200e-02],\n",
       "        [-4.0753e+00, -1.7133e-02],\n",
       "        [-1.1701e-02, -4.4539e+00]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "han(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
