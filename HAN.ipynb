{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"They think he's a good president because he's done things they like: appointing conservatives to the court and cutting taxes, for example. But every other normal Republican would have done the exact same things, made actual deals to get much more, and they'd have left out all the ridiculous drama that keeps Trump's approval so low and his accomplishments so meager.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns = [\"sentence\"])\n",
    "\n",
    "df[\"sentence\"] = sentences\n",
    "df[\"sentence\"] = df.sentence.map(lambda s :  s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words'] = df.sentence.map(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [they, think, he, 's, a, good, president, beca...\n",
       "1    [but, every, other, normal, republican, would,...\n",
       "Name: words, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_len = df.words.map(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "vocab = list(set(itertools.chain.from_iterable(df.words.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to',\n",
       " 'all',\n",
       " 'done',\n",
       " 'the',\n",
       " 'deals',\n",
       " 'republican',\n",
       " 'so',\n",
       " 'but',\n",
       " 'made',\n",
       " 'same',\n",
       " 'think',\n",
       " 'much',\n",
       " 'court',\n",
       " 'because',\n",
       " ':',\n",
       " 'actual',\n",
       " \"'d\",\n",
       " 'they',\n",
       " 'good',\n",
       " 'have',\n",
       " 'out',\n",
       " 'low',\n",
       " 'conservatives',\n",
       " \"'s\",\n",
       " 'example',\n",
       " 'more',\n",
       " 'that',\n",
       " 'keeps',\n",
       " 'meager',\n",
       " 'drama',\n",
       " 'for',\n",
       " 'a',\n",
       " 'would',\n",
       " 'he',\n",
       " 'things',\n",
       " 'appointing',\n",
       " 'other',\n",
       " 'exact',\n",
       " 'left',\n",
       " 'accomplishments',\n",
       " 'normal',\n",
       " 'like',\n",
       " 'president',\n",
       " 'get',\n",
       " 'approval',\n",
       " 'every',\n",
       " '.',\n",
       " 'ridiculous',\n",
       " ',',\n",
       " 'taxes',\n",
       " 'cutting',\n",
       " 'trump',\n",
       " 'his',\n",
       " 'and']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "?re.match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='all'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(\"\\w+\",vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matcher(word):\n",
    "    return re.match(\"\\w+\", word)\n",
    "\n",
    "vocab = list(filter(matcher, itertools.chain.from_iterable(df.words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab += [\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they',\n",
       " 'think',\n",
       " 'he',\n",
       " 'a',\n",
       " 'good',\n",
       " 'president',\n",
       " 'because',\n",
       " 'he',\n",
       " 'done',\n",
       " 'things',\n",
       " 'they',\n",
       " 'like',\n",
       " 'appointing',\n",
       " 'conservatives',\n",
       " 'to',\n",
       " 'the',\n",
       " 'court',\n",
       " 'and',\n",
       " 'cutting',\n",
       " 'taxes',\n",
       " 'for',\n",
       " 'example',\n",
       " 'but',\n",
       " 'every',\n",
       " 'other',\n",
       " 'normal',\n",
       " 'republican',\n",
       " 'would',\n",
       " 'have',\n",
       " 'done',\n",
       " 'the',\n",
       " 'exact',\n",
       " 'same',\n",
       " 'things',\n",
       " 'made',\n",
       " 'actual',\n",
       " 'deals',\n",
       " 'to',\n",
       " 'get',\n",
       " 'much',\n",
       " 'more',\n",
       " 'and',\n",
       " 'they',\n",
       " 'have',\n",
       " 'left',\n",
       " 'out',\n",
       " 'all',\n",
       " 'the',\n",
       " 'ridiculous',\n",
       " 'drama',\n",
       " 'that',\n",
       " 'keeps',\n",
       " 'trump',\n",
       " 'approval',\n",
       " 'so',\n",
       " 'low',\n",
       " 'and',\n",
       " 'his',\n",
       " 'accomplishments',\n",
       " 'so',\n",
       " 'meager',\n",
       " '<unk>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2vocab = {\n",
    "    index: word\n",
    "    for index, word in enumerate(vocab)\n",
    "}\n",
    "\n",
    "vocab2index = {\n",
    "    word: index\n",
    "    for index, word in enumerate(vocab)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'they': 42,\n",
       " 'think': 1,\n",
       " 'he': 7,\n",
       " 'a': 3,\n",
       " 'good': 4,\n",
       " 'president': 5,\n",
       " 'because': 6,\n",
       " 'done': 29,\n",
       " 'things': 33,\n",
       " 'like': 11,\n",
       " 'appointing': 12,\n",
       " 'conservatives': 13,\n",
       " 'to': 37,\n",
       " 'the': 47,\n",
       " 'court': 16,\n",
       " 'and': 56,\n",
       " 'cutting': 18,\n",
       " 'taxes': 19,\n",
       " 'for': 20,\n",
       " 'example': 21,\n",
       " 'but': 22,\n",
       " 'every': 23,\n",
       " 'other': 24,\n",
       " 'normal': 25,\n",
       " 'republican': 26,\n",
       " 'would': 27,\n",
       " 'have': 43,\n",
       " 'exact': 31,\n",
       " 'same': 32,\n",
       " 'made': 34,\n",
       " 'actual': 35,\n",
       " 'deals': 36,\n",
       " 'get': 38,\n",
       " 'much': 39,\n",
       " 'more': 40,\n",
       " 'left': 44,\n",
       " 'out': 45,\n",
       " 'all': 46,\n",
       " 'ridiculous': 48,\n",
       " 'drama': 49,\n",
       " 'that': 50,\n",
       " 'keeps': 51,\n",
       " 'trump': 52,\n",
       " 'approval': 53,\n",
       " 'so': 59,\n",
       " 'low': 55,\n",
       " 'his': 57,\n",
       " 'accomplishments': 58,\n",
       " 'meager': 60,\n",
       " '<unk>': 61}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_index(word):\n",
    "    index = vocab2index.get(\n",
    "        word,\n",
    "        vocab2index[\"<unk>\"]\n",
    "    )\n",
    "    return index\n",
    "\n",
    "df[\"word_indices\"] = df.words.map(\n",
    "    lambda words: list(map(get_word_index, words))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [42, 1, 7, 61, 3, 4, 5, 6, 7, 61, 29, 33, 42, ...\n",
       "1    [22, 23, 24, 25, 26, 27, 43, 29, 47, 31, 32, 3...\n",
       "Name: word_indices, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 1, 7, 61, 3, 4, 5, 6, 7, 61, 29, 33, 42, 11, 61, 12, 13, 37, 47, 16, 56, 18, 19, 61, 20, 21, 61]\n",
      "[22, 23, 24, 25, 26, 27, 43, 29, 47, 31, 32, 33, 61, 34, 35, 36, 37, 38, 39, 40, 61, 56, 42, 61, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 61, 53, 59, 55, 56, 57, 58, 59, 60, 61]\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def list2var(l):\n",
    "    print(l)\n",
    "    tensor = torch.LongTensor(l)\n",
    "    return Variable(tensor)\n",
    "\n",
    "variables = df.word_indices.map(list2var).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "seq = pad_sequence(variables, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(num_embeddings=len(vocab), embedding_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = embedding(seq[0])\n",
    "b = embedding(seq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 44, 100])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.stack([a,b], dim=0)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42,  1,  7, 61,  3,  4,  5,  6,  7, 61, 29, 33, 42, 11, 61, 12, 13, 37,\n",
       "         47, 16, 56, 18, 19, 61, 20, 21, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [22, 23, 24, 25, 26, 27, 43, 29, 47, 31, 32, 33, 61, 34, 35, 36, 37, 38,\n",
       "         39, 40, 61, 56, 42, 61, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 61, 53,\n",
       "         59, 55, 56, 57, 58, 59, 60, 61]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "\n",
    "gru = WordGRU(100, len(vocab), bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 44, 200])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_0 = torch.zeros(2, 2, 100)\n",
    "o, h = gru(seq, h_0)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 sentences\n",
    "- 44 words in each\n",
    "- 100 dim of each word\n",
    "- PyTorch LSTM is only concerned with the last dimension (100)\n",
    "- For word attention all sentences( each sentence is a batch ) is padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = WordAttention(200)\n",
    "s_vec = attn(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 200])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 Sentences\n",
    "- Each sentence of size 200\n",
    "- A batch of documents would have shape: `[batch_size, max_sent_len, max_word_len]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0163e+01,  8.7290e+00,  3.4055e+01,  2.6654e+01,  2.5068e+01,\n",
       "          4.6261e+01, -3.5101e+01,  2.9657e+00,  1.8693e+01, -1.6703e+00,\n",
       "         -9.4082e+00, -3.0112e+01, -3.8391e+01, -3.8499e+01,  1.8975e+01,\n",
       "         -4.0459e+01,  1.1163e+01, -1.1295e+01, -3.2604e+01, -5.6510e+00,\n",
       "          3.4529e+01, -1.4267e+01, -7.2485e+00,  4.2787e+00, -2.5971e+01,\n",
       "         -1.1791e+01,  4.7805e+01, -3.7395e+01, -2.2510e+01,  2.1934e+01,\n",
       "          5.5025e+01, -1.8491e+01,  2.4144e+01,  1.3930e+01, -3.4532e+01,\n",
       "          2.4406e+01,  5.7057e+00,  2.7735e+01,  3.4079e+01, -2.8117e+01,\n",
       "         -8.7659e+00,  9.9341e+00, -1.1719e+01,  2.3641e+01, -2.2787e+01,\n",
       "          2.2190e+01, -2.9935e+01,  1.9158e+01, -5.9563e-01,  1.4123e+01,\n",
       "          1.3187e+01,  5.4976e+00,  2.8214e+01, -3.3311e+01,  5.7860e-01,\n",
       "         -1.3092e+01,  3.6241e+01,  2.0336e+00, -4.4440e+00, -1.2177e+01,\n",
       "         -1.3722e+01, -2.9056e+01,  1.8751e+01,  5.1652e+00,  1.4427e+00,\n",
       "          1.3212e+01, -1.4711e+01, -3.0682e+01, -7.4966e+00, -1.8418e+00,\n",
       "          3.8498e+01, -3.5162e+01, -2.0515e+01, -8.3721e+00,  3.2963e+01,\n",
       "          3.5957e+00,  4.4805e+00,  2.9991e+01, -1.8542e+01, -1.3542e+01,\n",
       "          3.5120e+00, -2.7945e+01,  3.7302e+01, -1.5421e+01,  2.0142e+01,\n",
       "          4.2402e+01,  7.0026e+00,  1.0996e+01, -1.3896e+01, -4.0256e+01,\n",
       "         -2.4211e+00, -4.8255e+00, -1.6944e+01,  2.1888e+01, -3.9795e+01,\n",
       "         -1.8049e+01, -1.0573e+01,  1.5801e+01,  3.1354e+01,  5.0180e+01,\n",
       "          2.0437e+00, -3.5099e+01, -4.1431e+01,  1.9599e+01, -2.6516e+01,\n",
       "          1.9017e+01, -1.3499e+01, -4.2645e+01,  1.8078e+01, -9.9385e+00,\n",
       "          2.0934e+01, -1.5673e+01,  2.7566e+01, -2.4835e+01,  2.7251e+01,\n",
       "         -1.0626e+00, -3.6832e+01, -2.4500e+01,  3.2355e+00, -3.3405e+01,\n",
       "         -3.2665e+01, -1.2855e+01, -1.2454e+01, -1.0889e+01, -3.7677e+01,\n",
       "         -1.8815e+01,  4.5583e+00, -1.2827e+01, -5.6515e+00, -1.5172e+01,\n",
       "         -2.4946e+01, -2.0493e-01, -3.3327e+00, -3.0207e+01, -1.8717e+00,\n",
       "          1.7497e+00, -5.7924e+00,  8.1299e+00,  1.8394e+00,  1.0966e+01,\n",
       "         -4.4808e+00,  1.9853e+01,  2.1366e+01, -9.4984e+00,  2.5927e+01,\n",
       "         -1.6901e+01, -2.0474e+01, -7.3098e+00,  2.3874e+01, -1.4756e+01,\n",
       "         -4.7075e+00,  1.8943e+01, -6.3480e+00,  1.1638e+01,  3.6971e+00,\n",
       "         -3.1536e+01, -3.3372e+01,  2.4057e+01,  2.7474e+01, -1.1329e+01,\n",
       "         -1.3399e+01, -1.3192e+01, -1.2572e+01,  4.1385e+00, -1.1554e+01,\n",
       "          1.7266e+01, -2.5394e+01,  1.7372e+01,  2.1726e+01,  3.5686e+01,\n",
       "          3.0849e+01, -6.2361e+00, -2.3725e+01,  1.6480e+01,  7.7292e+00,\n",
       "         -1.7759e+01,  6.4805e+00, -1.2841e+01,  3.7066e+01,  3.1914e+01,\n",
       "         -1.4607e+01, -9.1429e+00,  4.6330e+00,  2.0855e+01, -2.9037e+01,\n",
       "         -1.3030e+01, -1.2025e+01,  3.2730e+01, -6.9333e+00, -3.4600e+01,\n",
       "         -5.9087e+00,  4.7285e+00, -3.2914e+01, -2.5116e+01, -2.5095e+01,\n",
       "          6.0532e+00,  1.7496e+01, -2.3420e+01, -7.2012e+00, -9.2036e+00],\n",
       "        [-1.1106e+00,  6.5593e+00, -3.7516e+00, -8.2729e+00,  8.5937e+00,\n",
       "          1.3086e+01,  2.8899e+00, -5.2558e+00,  3.0655e+00, -1.2005e+00,\n",
       "          2.0005e+00, -6.2275e+00, -8.6832e+00, -6.1768e+00,  5.7570e+00,\n",
       "         -8.8239e+00,  9.2655e+00, -1.0250e+01,  7.4959e-01, -1.1957e+00,\n",
       "         -9.4775e+00, -9.0726e+00, -1.1365e+01,  5.1649e+00, -2.5243e+00,\n",
       "         -1.6199e+01, -1.2159e+01,  8.4302e+00,  4.6790e+00, -3.4631e+00,\n",
       "         -9.7208e-01,  6.7999e+00,  3.2146e+00,  3.9655e+00, -2.1437e+00,\n",
       "          1.0594e+01,  5.6903e+00,  6.7480e+00,  8.0764e+00,  4.2055e+00,\n",
       "         -2.2750e+00, -4.1675e+00,  3.7676e+00, -6.0514e+00,  3.0796e+00,\n",
       "         -2.2056e+00,  3.2916e+00,  2.4152e+00,  4.1140e+00, -8.9056e-03,\n",
       "          9.3266e+00, -6.1624e+00,  5.5422e+00,  8.8687e+00, -1.2418e+00,\n",
       "          1.9913e-01,  9.9102e+00,  1.1010e+01, -3.2384e+00, -2.9930e+00,\n",
       "         -5.3898e+00,  1.3239e+01, -1.2672e+00, -1.5141e+01,  1.4220e+00,\n",
       "          1.7694e+00, -8.6556e+00, -9.7142e-01, -6.4128e+00,  7.3550e+00,\n",
       "         -4.1263e+00,  3.6516e+00, -8.0764e+00, -1.1139e+01, -8.2908e+00,\n",
       "         -4.2458e-01,  5.6405e+00,  6.0711e+00,  1.3852e+01, -5.2045e+00,\n",
       "          6.1584e-01, -6.6138e+00, -3.3859e+00,  1.1869e+00,  8.7458e+00,\n",
       "          1.9661e+00,  2.3185e+00, -3.8521e+00,  5.9417e+00, -5.9434e+00,\n",
       "         -1.2463e+00, -1.5582e+01,  9.5357e+00,  9.5959e+00, -1.4815e+00,\n",
       "         -4.9258e+00, -5.7380e+00,  3.6754e+00,  1.1497e+01,  2.6511e+00,\n",
       "         -2.2560e+00, -9.3156e+00,  5.9290e-01, -1.1701e+01, -3.5555e+00,\n",
       "          2.9255e+00, -2.2641e+00, -1.0077e+01,  7.4922e+00,  2.6790e+00,\n",
       "          1.4348e+01, -1.1261e+00,  8.9646e+00, -1.0615e+01,  7.1413e+00,\n",
       "         -4.8090e+00,  3.7266e+00,  1.5347e+01,  1.6694e+00,  2.1973e+00,\n",
       "         -3.6868e+00, -8.3670e+00,  9.1261e+00, -9.4932e+00,  2.9300e+00,\n",
       "          3.9330e+00, -4.8951e+00,  5.3322e+00,  8.7786e-01,  7.1059e+00,\n",
       "          1.0550e+01, -1.0974e+01,  3.5434e+00,  2.4040e-01, -3.0786e+00,\n",
       "         -4.1826e-01, -1.1277e+01, -1.2923e+01,  1.2956e+01,  1.0339e+00,\n",
       "          2.2686e+00, -8.5530e+00, -5.9066e-01,  6.7078e+00, -1.1062e+01,\n",
       "         -1.2347e+00,  1.0696e+01,  5.5154e+00,  8.9729e-01, -7.2280e-01,\n",
       "          3.0965e+00, -5.0878e+00, -1.4875e+01, -1.7230e+01,  5.7352e+00,\n",
       "         -3.0686e+00,  1.2490e+00, -3.7295e+00, -7.5981e+00, -2.4828e+00,\n",
       "         -5.4625e+00,  5.0903e+00, -1.3269e+00, -1.1510e-02, -4.1866e+00,\n",
       "         -5.9573e+00, -2.4536e+00, -4.0999e+00, -1.9077e-01, -6.7522e+00,\n",
       "          1.9352e+00,  5.5627e+00,  1.3482e+01,  3.4906e+00, -4.3091e+00,\n",
       "          4.4216e+00,  2.3158e+00,  7.6241e+00, -7.9978e+00,  6.4085e-01,\n",
       "          1.9872e+00, -3.4587e+00, -1.3288e+00,  1.0309e+01,  4.2026e-01,\n",
       "         -5.2844e+00, -1.5466e+01,  5.2196e-01, -4.5212e+00,  2.8678e+00,\n",
       "         -9.0246e+00, -8.0871e+00,  1.7124e+00, -1.2930e+00, -5.6739e+00,\n",
       "         -5.9683e+00, -1.3016e+01, -1.0522e+01, -1.9545e+00,  8.4614e+00]],\n",
       "       grad_fn=<SumBackward2>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_gru = SentenceGRU(200, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 200])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_vec.unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_0_s = torch.zeros(2,1,100)\n",
    "sentence_output, h_s = sentence_gru(s_vec.unsqueeze(dim=0), h_0_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 200])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_attn = SentenceAttention(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vec = s_attn(sentence_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shikhar/Documents/HAN/models.py:186: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  o = self.softmax(o)\n"
     ]
    }
   ],
   "source": [
    "output_layer = OutputLayer(200,2)\n",
    "output = output_layer(d_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1239, -2.1495]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.squeeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = loss(output, torch.LongTensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
