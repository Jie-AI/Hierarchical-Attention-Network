{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"They think he's a good president because he's done things they like: appointing conservatives to the court and cutting taxes, for example. But every other normal Republican would have done the exact same things, made actual deals to get much more, and they'd have left out all the ridiculous drama that keeps Trump's approval so low and his accomplishments so meager.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns = [\"sentence\"])\n",
    "\n",
    "df[\"sentence\"] = sentences\n",
    "df[\"sentence\"] = df.sentence.map(lambda s :  s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words'] = df.sentence.map(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [they, think, he, 's, a, good, president, beca...\n",
       "1    [but, every, other, normal, republican, would,...\n",
       "Name: words, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_len = df.words.map(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "vocab = list(set(itertools.chain.from_iterable(df.words.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['appointing',\n",
       " ',',\n",
       " 'would',\n",
       " 'keeps',\n",
       " 'court',\n",
       " 'same',\n",
       " 'out',\n",
       " 'all',\n",
       " 'a',\n",
       " 'made',\n",
       " ':',\n",
       " 'taxes',\n",
       " 'more',\n",
       " 'low',\n",
       " 'the',\n",
       " 'republican',\n",
       " 'much',\n",
       " 'done',\n",
       " 'they',\n",
       " 'because',\n",
       " 'have',\n",
       " 'so',\n",
       " \"'d\",\n",
       " 'every',\n",
       " 'other',\n",
       " 'approval',\n",
       " 'and',\n",
       " 'actual',\n",
       " 'things',\n",
       " 'cutting',\n",
       " 'example',\n",
       " 'exact',\n",
       " 'like',\n",
       " 'president',\n",
       " 'ridiculous',\n",
       " 'trump',\n",
       " 'accomplishments',\n",
       " \"'s\",\n",
       " 'his',\n",
       " 'deals',\n",
       " 'but',\n",
       " 'that',\n",
       " 'he',\n",
       " 'meager',\n",
       " 'to',\n",
       " 'for',\n",
       " 'conservatives',\n",
       " '.',\n",
       " 'get',\n",
       " 'normal',\n",
       " 'think',\n",
       " 'left',\n",
       " 'good',\n",
       " 'drama']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "?re.match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match(\"\\w+\",vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matcher(word):\n",
    "    return re.match(\"\\w+\", word)\n",
    "\n",
    "vocab = list(filter(matcher, itertools.chain.from_iterable(df.words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab += [\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they',\n",
       " 'think',\n",
       " 'he',\n",
       " 'a',\n",
       " 'good',\n",
       " 'president',\n",
       " 'because',\n",
       " 'he',\n",
       " 'done',\n",
       " 'things',\n",
       " 'they',\n",
       " 'like',\n",
       " 'appointing',\n",
       " 'conservatives',\n",
       " 'to',\n",
       " 'the',\n",
       " 'court',\n",
       " 'and',\n",
       " 'cutting',\n",
       " 'taxes',\n",
       " 'for',\n",
       " 'example',\n",
       " 'but',\n",
       " 'every',\n",
       " 'other',\n",
       " 'normal',\n",
       " 'republican',\n",
       " 'would',\n",
       " 'have',\n",
       " 'done',\n",
       " 'the',\n",
       " 'exact',\n",
       " 'same',\n",
       " 'things',\n",
       " 'made',\n",
       " 'actual',\n",
       " 'deals',\n",
       " 'to',\n",
       " 'get',\n",
       " 'much',\n",
       " 'more',\n",
       " 'and',\n",
       " 'they',\n",
       " 'have',\n",
       " 'left',\n",
       " 'out',\n",
       " 'all',\n",
       " 'the',\n",
       " 'ridiculous',\n",
       " 'drama',\n",
       " 'that',\n",
       " 'keeps',\n",
       " 'trump',\n",
       " 'approval',\n",
       " 'so',\n",
       " 'low',\n",
       " 'and',\n",
       " 'his',\n",
       " 'accomplishments',\n",
       " 'so',\n",
       " 'meager',\n",
       " '<unk>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2vocab = {\n",
    "    index: word\n",
    "    for index, word in enumerate(vocab)\n",
    "}\n",
    "\n",
    "vocab2index = {\n",
    "    word: index\n",
    "    for index, word in enumerate(vocab)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'they': 42,\n",
       " 'think': 1,\n",
       " 'he': 7,\n",
       " 'a': 3,\n",
       " 'good': 4,\n",
       " 'president': 5,\n",
       " 'because': 6,\n",
       " 'done': 29,\n",
       " 'things': 33,\n",
       " 'like': 11,\n",
       " 'appointing': 12,\n",
       " 'conservatives': 13,\n",
       " 'to': 37,\n",
       " 'the': 47,\n",
       " 'court': 16,\n",
       " 'and': 56,\n",
       " 'cutting': 18,\n",
       " 'taxes': 19,\n",
       " 'for': 20,\n",
       " 'example': 21,\n",
       " 'but': 22,\n",
       " 'every': 23,\n",
       " 'other': 24,\n",
       " 'normal': 25,\n",
       " 'republican': 26,\n",
       " 'would': 27,\n",
       " 'have': 43,\n",
       " 'exact': 31,\n",
       " 'same': 32,\n",
       " 'made': 34,\n",
       " 'actual': 35,\n",
       " 'deals': 36,\n",
       " 'get': 38,\n",
       " 'much': 39,\n",
       " 'more': 40,\n",
       " 'left': 44,\n",
       " 'out': 45,\n",
       " 'all': 46,\n",
       " 'ridiculous': 48,\n",
       " 'drama': 49,\n",
       " 'that': 50,\n",
       " 'keeps': 51,\n",
       " 'trump': 52,\n",
       " 'approval': 53,\n",
       " 'so': 59,\n",
       " 'low': 55,\n",
       " 'his': 57,\n",
       " 'accomplishments': 58,\n",
       " 'meager': 60,\n",
       " '<unk>': 61}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_index(word):\n",
    "    index = vocab2index.get(\n",
    "        word,\n",
    "        vocab2index[\"<unk>\"]\n",
    "    )\n",
    "    return index\n",
    "\n",
    "df[\"word_indices\"] = df.words.map(\n",
    "    lambda words: list(map(get_word_index, words))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [42, 1, 7, 61, 3, 4, 5, 6, 7, 61, 29, 33, 42, ...\n",
       "1    [22, 23, 24, 25, 26, 27, 43, 29, 47, 31, 32, 3...\n",
       "Name: word_indices, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 1, 7, 61, 3, 4, 5, 6, 7, 61, 29, 33, 42, 11, 61, 12, 13, 37, 47, 16, 56, 18, 19, 61, 20, 21, 61]\n",
      "[22, 23, 24, 25, 26, 27, 43, 29, 47, 31, 32, 33, 61, 34, 35, 36, 37, 38, 39, 40, 61, 56, 42, 61, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 61, 53, 59, 55, 56, 57, 58, 59, 60, 61]\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def list2var(l):\n",
    "    print(l)\n",
    "    tensor = torch.LongTensor(l)\n",
    "    return Variable(tensor)\n",
    "\n",
    "variables = df.word_indices.map(list2var).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "seq = pad_sequence(variables, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(num_embeddings=len(vocab), embedding_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = embedding(seq[0])\n",
    "b = embedding(seq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 44, 100])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.stack([a,b], dim=0)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42,  1,  7, 61,  3,  4,  5,  6,  7, 61, 29, 33, 42, 11, 61, 12, 13, 37,\n",
       "         47, 16, 56, 18, 19, 61, 20, 21, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [22, 23, 24, 25, 26, 27, 43, 29, 47, 31, 32, 33, 61, 34, 35, 36, 37, 38,\n",
       "         39, 40, 61, 56, 42, 61, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 61, 53,\n",
       "         59, 55, 56, 57, 58, 59, 60, 61]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim, vocab_size, lstm_size=100, bidirectional=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_size, bidirectional=bidirectional, batch_first=True)\n",
    "    \n",
    "    def seq_to_embedding(self, seq):\n",
    "        '''\n",
    "        Use the padded sequence to get embeddings\n",
    "        '''\n",
    "        embeds = []\n",
    "        \n",
    "        for s in seq:\n",
    "            embeds.append(self.embedding(s))\n",
    "            \n",
    "        return torch.stack(embeds, dim=0)\n",
    "    \n",
    "    def forward(self, input, hidden, cell):\n",
    "        batch = self.seq_to_embedding(input)\n",
    "        output, (hidden,cell) = self.lstm(batch, (hidden, cell))\n",
    "        \n",
    "        return output, hidden, cell\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = WordLSTM(100, len(vocab), bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 44, 200])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_0 = torch.zeros(2, 2, 100)\n",
    "c_0 = torch.zeros(2, 2, 100)\n",
    "o, h, cs = lstm(seq, h_0,c_0)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 sentences\n",
    "- 44 words in each\n",
    "- 100 dim of each word\n",
    "- PyTorch LSTM is only concerned with the last dimension (100)\n",
    "- For word attention all sentences( each sentence is a batch ) is padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordAttn(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.activation = nn.functional.tanh\n",
    "        self.word_context = nn.Parameter(torch.randn(hidden_size,1))\n",
    "    \n",
    "    def forward(self, word_outputs):\n",
    "        \n",
    "        o = self.linear(word_outputs)\n",
    "        o = self.activation(o)\n",
    "        o = torch.matmul(o, self.word_context)\n",
    "        o = torch.mul(o, word_outputs)\n",
    "        o = torch.sum(o, dim=0)\n",
    "        \n",
    "        return o\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shikhar/.conda/envs/ml/lib/python3.6/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "attn = WordAttn(200)\n",
    "s_vec = attn(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0057, -0.1097,  0.0328,  ..., -0.3123,  0.2545, -0.2326],\n",
       "        [ 0.0394, -0.0855,  0.0560,  ..., -0.2262,  0.2011, -0.0985],\n",
       "        [-0.0079, -0.0233,  0.0218,  ...,  0.1382, -0.1077,  0.0372],\n",
       "        ...,\n",
       "        [-0.0120, -0.1128, -0.0554,  ..., -0.0325, -0.1447,  0.0488],\n",
       "        [-0.1920, -0.1302,  0.1134,  ...,  0.1166,  0.0937, -0.0985],\n",
       "        [-0.3153,  0.0516, -0.1962,  ..., -0.0024,  0.2650, -0.2625]],\n",
       "       grad_fn=<SumBackward2>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
