{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"They think he's a good president because he's done things they like: appointing conservatives to the court and cutting taxes, for example. But every other normal Republican would have done the exact same things, made actual deals to get much more, and they'd have left out all the ridiculous drama that keeps Trump's approval so low and his accomplishments so meager.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns = [\"sentence\"])\n",
    "\n",
    "df[\"sentence\"] = sentences\n",
    "df[\"sentence\"] = df.sentence.map(lambda s :  s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words'] = df.sentence.map(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [they, think, he, 's, a, good, president, beca...\n",
       "1    [but, every, other, normal, republican, would,...\n",
       "Name: words, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_len = df.words.map(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "vocab = list(set(itertools.chain.from_iterable(df.words.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['left',\n",
       " 'same',\n",
       " 'deals',\n",
       " 'he',\n",
       " 'more',\n",
       " 'low',\n",
       " 'a',\n",
       " 'for',\n",
       " 'things',\n",
       " 'drama',\n",
       " 'accomplishments',\n",
       " 'every',\n",
       " 'have',\n",
       " 'so',\n",
       " 'approval',\n",
       " 'because',\n",
       " 'and',\n",
       " 'but',\n",
       " 'actual',\n",
       " 'think',\n",
       " 'president',\n",
       " 'example',\n",
       " 'the',\n",
       " 'good',\n",
       " 'normal',\n",
       " 'court',\n",
       " 'would',\n",
       " 'out',\n",
       " 'all',\n",
       " 'get',\n",
       " 'they',\n",
       " 'republican',\n",
       " \"'d\",\n",
       " 'done',\n",
       " 'conservatives',\n",
       " ',',\n",
       " 'keeps',\n",
       " 'meager',\n",
       " 'exact',\n",
       " 'like',\n",
       " 'to',\n",
       " \"'s\",\n",
       " '.',\n",
       " 'that',\n",
       " 'other',\n",
       " 'his',\n",
       " 'taxes',\n",
       " ':',\n",
       " 'cutting',\n",
       " 'much',\n",
       " 'ridiculous',\n",
       " 'trump',\n",
       " 'appointing',\n",
       " 'made']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "?re.match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 4), match='same'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(\"\\w+\",vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matcher(word):\n",
    "    return re.match(\"\\w+\", word)\n",
    "\n",
    "vocab = list(filter(matcher, itertools.chain.from_iterable(df.words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab += [\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they',\n",
       " 'think',\n",
       " 'he',\n",
       " 'a',\n",
       " 'good',\n",
       " 'president',\n",
       " 'because',\n",
       " 'he',\n",
       " 'done',\n",
       " 'things',\n",
       " 'they',\n",
       " 'like',\n",
       " 'appointing',\n",
       " 'conservatives',\n",
       " 'to',\n",
       " 'the',\n",
       " 'court',\n",
       " 'and',\n",
       " 'cutting',\n",
       " 'taxes',\n",
       " 'for',\n",
       " 'example',\n",
       " 'but',\n",
       " 'every',\n",
       " 'other',\n",
       " 'normal',\n",
       " 'republican',\n",
       " 'would',\n",
       " 'have',\n",
       " 'done',\n",
       " 'the',\n",
       " 'exact',\n",
       " 'same',\n",
       " 'things',\n",
       " 'made',\n",
       " 'actual',\n",
       " 'deals',\n",
       " 'to',\n",
       " 'get',\n",
       " 'much',\n",
       " 'more',\n",
       " 'and',\n",
       " 'they',\n",
       " 'have',\n",
       " 'left',\n",
       " 'out',\n",
       " 'all',\n",
       " 'the',\n",
       " 'ridiculous',\n",
       " 'drama',\n",
       " 'that',\n",
       " 'keeps',\n",
       " 'trump',\n",
       " 'approval',\n",
       " 'so',\n",
       " 'low',\n",
       " 'and',\n",
       " 'his',\n",
       " 'accomplishments',\n",
       " 'so',\n",
       " 'meager',\n",
       " '<unk>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2vocab = {\n",
    "    index: word\n",
    "    for index, word in enumerate(vocab)\n",
    "}\n",
    "\n",
    "vocab2index = {\n",
    "    word: index\n",
    "    for index, word in enumerate(vocab)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'they': 42,\n",
       " 'think': 1,\n",
       " 'he': 7,\n",
       " 'a': 3,\n",
       " 'good': 4,\n",
       " 'president': 5,\n",
       " 'because': 6,\n",
       " 'done': 29,\n",
       " 'things': 33,\n",
       " 'like': 11,\n",
       " 'appointing': 12,\n",
       " 'conservatives': 13,\n",
       " 'to': 37,\n",
       " 'the': 47,\n",
       " 'court': 16,\n",
       " 'and': 56,\n",
       " 'cutting': 18,\n",
       " 'taxes': 19,\n",
       " 'for': 20,\n",
       " 'example': 21,\n",
       " 'but': 22,\n",
       " 'every': 23,\n",
       " 'other': 24,\n",
       " 'normal': 25,\n",
       " 'republican': 26,\n",
       " 'would': 27,\n",
       " 'have': 43,\n",
       " 'exact': 31,\n",
       " 'same': 32,\n",
       " 'made': 34,\n",
       " 'actual': 35,\n",
       " 'deals': 36,\n",
       " 'get': 38,\n",
       " 'much': 39,\n",
       " 'more': 40,\n",
       " 'left': 44,\n",
       " 'out': 45,\n",
       " 'all': 46,\n",
       " 'ridiculous': 48,\n",
       " 'drama': 49,\n",
       " 'that': 50,\n",
       " 'keeps': 51,\n",
       " 'trump': 52,\n",
       " 'approval': 53,\n",
       " 'so': 59,\n",
       " 'low': 55,\n",
       " 'his': 57,\n",
       " 'accomplishments': 58,\n",
       " 'meager': 60,\n",
       " '<unk>': 61}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_index(word):\n",
    "    index = vocab2index.get(\n",
    "        word,\n",
    "        vocab2index[\"<unk>\"]\n",
    "    )\n",
    "    return index\n",
    "\n",
    "df[\"word_indices\"] = df.words.map(\n",
    "    lambda words: list(map(get_word_index, words))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [42, 1, 7, 61, 3, 4, 5, 6, 7, 61, 29, 33, 42, ...\n",
       "1    [22, 23, 24, 25, 26, 27, 43, 29, 47, 31, 32, 3...\n",
       "Name: word_indices, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 1, 7, 61, 3, 4, 5, 6, 7, 61, 29, 33, 42, 11, 61, 12, 13, 37, 47, 16, 56, 18, 19, 61, 20, 21, 61]\n",
      "[22, 23, 24, 25, 26, 27, 43, 29, 47, 31, 32, 33, 61, 34, 35, 36, 37, 38, 39, 40, 61, 56, 42, 61, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 61, 53, 59, 55, 56, 57, 58, 59, 60, 61]\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def list2var(l):\n",
    "    print(l)\n",
    "    tensor = torch.LongTensor(l)\n",
    "    return Variable(tensor)\n",
    "\n",
    "variables = df.word_indices.map(list2var).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "seq = pad_sequence(variables, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(num_embeddings=len(vocab), embedding_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = embedding(seq[0])\n",
    "b = embedding(seq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 44, 100])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.stack([a,b], dim=0)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42,  1,  7, 61,  3,  4,  5,  6,  7, 61, 29, 33, 42, 11, 61, 12, 13, 37,\n",
       "         47, 16, 56, 18, 19, 61, 20, 21, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [22, 23, 24, 25, 26, 27, 43, 29, 47, 31, 32, 33, 61, 34, 35, 36, 37, 38,\n",
       "         39, 40, 61, 56, 42, 61, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 61, 53,\n",
       "         59, 55, 56, 57, 58, 59, 60, 61]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim, vocab_size, lstm_size=100, bidirectional=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_size, bidirectional=bidirectional, batch_first=True)\n",
    "    \n",
    "    def seq_to_embedding(self, seq):\n",
    "        '''\n",
    "        Use the padded sequence to get embeddings\n",
    "        '''\n",
    "        embeds = []\n",
    "        \n",
    "        for s in seq:\n",
    "            embeds.append(self.embedding(s))\n",
    "            \n",
    "        return torch.stack(embeds, dim=0)\n",
    "    \n",
    "    def forward(self, input, hidden, cell):\n",
    "        batch = self.seq_to_embedding(input)\n",
    "        output, (hidden,cell) = self.lstm(batch, (hidden, cell))\n",
    "        \n",
    "        return output, hidden, cell\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = WordLSTM(100, len(vocab), bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 44, 200])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_0 = torch.zeros(2, 2, 100)\n",
    "c_0 = torch.zeros(2, 2, 100)\n",
    "o, h, cs = lstm(seq, h_0,c_0)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 sentences\n",
    "- 44 words in each\n",
    "- 100 dim of each word\n",
    "- PyTorch LSTM is only concerned with the last dimension (100)\n",
    "- For word attention all sentences( each sentence is a batch ) is padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordAttn(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.activation = nn.functional.tanh\n",
    "        self.word_context = nn.Parameter(torch.randn(hidden_size,1))\n",
    "    \n",
    "    def forward(self, word_outputs):\n",
    "        \n",
    "        o = self.linear(word_outputs)\n",
    "        o = self.activation(o)\n",
    "        o = torch.matmul(o, self.word_context)\n",
    "        o = torch.mul(o, word_outputs)\n",
    "        o = torch.sum(o, dim=1) ## Sum along the words\n",
    "        \n",
    "        return o\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = WordAttn(200)\n",
    "s_vec = attn(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 200])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3239e+00,  1.7234e+00,  2.4380e+00,  2.3324e+00,  2.8235e-01,\n",
       "          5.0313e+00,  6.4516e+00, -2.9920e+00,  2.4822e-01,  3.5835e+00,\n",
       "         -2.9361e+00,  3.6338e+00, -2.2503e+00, -2.6444e-01, -2.7912e+00,\n",
       "          8.9907e-01,  3.0398e+00,  1.1397e+00,  2.0828e+00, -6.8375e-01,\n",
       "         -1.6930e+00,  1.6707e+00,  2.7948e+00, -1.2604e+00,  3.1361e+00,\n",
       "         -4.8111e+00,  1.7177e+00, -4.5576e-01, -2.9207e+00,  1.8649e+00,\n",
       "         -5.1941e-01, -2.2394e+00,  1.4448e-01,  1.3136e+00,  5.0659e+00,\n",
       "          1.1054e+00, -3.1563e+00, -3.5277e+00, -1.7769e+00,  2.6171e+00,\n",
       "         -2.2232e+00,  1.0031e-01, -1.1388e+00, -1.3125e+00, -6.0528e-01,\n",
       "         -1.0570e+00, -2.9848e+00, -3.5599e-01, -2.7809e+00, -1.2778e+00,\n",
       "          1.4552e+00,  3.9595e-01, -1.5901e+00,  6.2451e-01,  1.9781e+00,\n",
       "          2.5839e+00,  2.2140e-01,  3.2322e-01,  1.2642e+00, -2.2887e+00,\n",
       "         -6.2425e-01,  3.7624e-01,  4.1016e+00,  1.4536e+00,  1.2577e+00,\n",
       "          1.3359e+00,  5.4895e+00, -3.4030e+00, -1.3422e+00,  3.1488e+00,\n",
       "          2.5606e+00, -7.1104e-01, -8.2275e+00,  3.5448e+00,  7.5643e+00,\n",
       "         -8.4953e+00,  2.3430e+00, -2.1239e+00, -7.7678e-01,  8.0370e-01,\n",
       "          4.4917e-01,  3.8749e+00, -7.1516e-01,  5.0273e-01,  6.0612e+00,\n",
       "          1.5778e+00, -1.1166e+00, -3.5135e+00,  5.1213e+00, -2.5571e+00,\n",
       "         -3.6948e-01,  1.2274e+00,  4.6757e+00,  3.4946e+00, -4.3967e-01,\n",
       "          3.6400e+00,  1.9129e+00,  1.8620e+00,  1.4606e+00, -8.1863e-01,\n",
       "         -1.1099e+00, -4.3035e+00,  1.9107e+00, -5.9413e-01,  1.4780e+00,\n",
       "         -4.2214e+00,  3.4691e+00,  3.7707e+00, -1.2530e+00,  3.7840e+00,\n",
       "         -3.6738e-01, -2.6168e+00, -3.3592e-01,  5.6047e+00,  5.5760e+00,\n",
       "          6.4432e-01, -4.7748e+00, -4.0928e+00, -5.5134e-01, -4.9877e+00,\n",
       "         -4.5169e+00,  1.2633e+00,  2.9367e-01,  9.9657e-01, -1.9405e+00,\n",
       "         -5.8446e-04, -3.6840e+00,  9.2483e-02, -3.2857e-01, -1.2039e+00,\n",
       "          2.6381e+00, -3.1590e+00, -8.1584e-01, -4.8629e+00,  1.3945e+00,\n",
       "          7.2777e-01,  2.3775e+00, -3.5448e+00,  1.6009e+00,  6.3029e-01,\n",
       "         -4.7670e+00, -5.9682e-01,  3.0758e+00,  1.4961e+00, -1.7209e+00,\n",
       "          2.6380e+00,  3.6426e+00,  2.6713e+00, -2.4559e+00, -5.4916e+00,\n",
       "          4.3874e+00, -1.7468e+00,  4.3637e+00, -8.3861e-01,  7.9297e+00,\n",
       "         -1.8268e+00, -5.4879e-01,  7.8933e-01,  4.1767e+00,  1.1784e+00,\n",
       "         -1.3822e+00,  2.1488e+00, -2.6869e+00, -7.4887e-01,  2.3061e+00,\n",
       "         -1.3618e+00,  6.6182e-01, -2.7611e+00, -1.4354e+00,  2.3642e+00,\n",
       "         -6.1614e-01,  1.6528e+00,  9.7918e-01, -3.1646e+00, -6.7683e-01,\n",
       "         -2.2109e+00, -4.9306e-01,  1.7900e+00, -2.2274e+00, -4.3819e+00,\n",
       "          5.1982e-01,  7.5809e+00,  2.3000e+00, -4.2806e+00, -2.5647e+00,\n",
       "         -2.9792e+00, -4.4446e+00,  4.9966e+00,  4.7171e+00, -2.1980e+00,\n",
       "         -2.4546e+00,  4.0958e+00,  3.3536e+00,  1.1186e+00, -1.3405e+00,\n",
       "         -2.2290e+00, -1.2228e+00,  1.8777e+00,  4.4186e+00,  2.7040e+00],\n",
       "        [-1.4461e+00, -4.2029e-01,  6.4556e-01,  1.2628e+00, -1.4123e+00,\n",
       "          1.4976e+00,  1.7509e+00, -3.4296e+00,  9.4291e-01,  6.1021e-01,\n",
       "         -4.4921e+00,  1.7650e+00,  2.9337e-03,  1.5412e+00, -4.7199e-01,\n",
       "          9.3199e-01,  3.3136e+00,  2.3245e+00, -8.5350e-01, -2.2099e+00,\n",
       "         -4.2664e-01,  9.6375e-02,  1.8225e+00,  2.3343e+00, -3.9353e+00,\n",
       "         -1.6123e+00,  2.2675e+00,  2.6236e+00,  7.8969e-01, -1.1342e+00,\n",
       "          4.0429e+00,  1.1331e+00,  2.1626e+00,  3.2022e-01,  2.7464e+00,\n",
       "          1.2646e+00,  2.7239e-02, -4.4897e-01, -3.3943e+00,  3.6846e+00,\n",
       "         -3.1642e+00,  3.5322e-01, -2.9332e+00, -4.8302e-02,  1.9984e+00,\n",
       "         -4.1756e+00,  3.9651e+00,  1.3420e+00, -9.3567e-01, -1.0651e+00,\n",
       "          9.4053e-01,  1.2579e+00, -1.1863e+00,  1.7075e-01,  2.0781e+00,\n",
       "          2.8904e-03, -1.7776e-01,  2.8231e+00,  5.0020e-02, -2.6043e+00,\n",
       "         -2.0374e+00,  2.3841e+00,  1.1014e+00,  7.3605e-01,  1.8868e+00,\n",
       "         -1.4232e-01,  1.9770e-01,  1.6604e+00,  1.6510e+00,  2.1210e+00,\n",
       "          1.3344e+00,  3.9614e-01, -2.0113e+00,  1.4801e-01,  1.7866e+00,\n",
       "         -5.5197e+00,  5.3240e-01,  2.3847e+00,  1.7118e+00,  2.9177e-01,\n",
       "          2.3829e+00,  4.9198e-01,  2.6091e+00,  2.6604e+00, -9.3243e-01,\n",
       "         -2.5309e+00,  1.1439e+00,  2.0028e+00,  3.8648e+00, -4.4247e-01,\n",
       "         -1.6538e+00,  2.6359e+00,  7.1119e-01, -4.7155e+00,  2.0628e-02,\n",
       "         -4.6439e-01, -6.4468e-01, -8.7816e-01, -3.1111e+00,  1.8597e+00,\n",
       "         -1.6466e+00, -2.3701e+00,  1.8225e+00, -6.4895e-03, -1.8921e+00,\n",
       "         -4.0733e+00,  1.8298e+00,  2.5066e+00, -6.2701e+00,  3.8775e+00,\n",
       "          4.5219e+00, -3.5054e+00, -1.1945e-01,  1.7397e+00,  7.7310e-01,\n",
       "          2.2409e-01, -9.5398e-01,  3.7251e+00,  2.0861e+00, -2.4552e+00,\n",
       "          1.5647e+00,  2.5848e+00,  4.7869e-01,  1.6684e+00, -7.9754e-01,\n",
       "         -4.6406e+00, -1.1537e+00, -2.0075e+00, -3.9087e+00, -2.2867e+00,\n",
       "          5.1008e+00,  1.3172e+00, -6.1995e+00, -1.0169e+00,  4.4612e+00,\n",
       "         -9.7845e-01,  4.3326e+00,  2.5429e+00,  3.0224e+00, -1.7982e+00,\n",
       "          1.5758e+00, -4.1414e+00,  2.8127e+00,  2.2967e+00, -4.1275e+00,\n",
       "          1.1175e+00, -4.3107e-01,  3.5808e-01, -2.0633e-01,  3.9227e-01,\n",
       "         -5.0785e-01,  2.0782e+00,  4.6288e-01, -2.3912e+00,  5.2702e+00,\n",
       "         -2.5945e+00, -1.6947e-01, -2.8254e-01, -8.7102e-01,  1.9934e+00,\n",
       "         -3.1465e+00, -3.2724e+00, -7.3841e-02, -7.3463e+00, -1.0359e+00,\n",
       "         -4.3833e+00,  1.1324e+00, -8.8049e-01,  2.7605e+00, -7.0994e-01,\n",
       "          4.8131e+00, -1.6649e+00,  1.2961e+00, -1.7006e+00,  1.5516e+00,\n",
       "         -3.7793e-01,  4.6554e+00, -2.6048e+00, -8.8544e-01,  1.3594e+00,\n",
       "          7.8767e-01,  3.8283e+00, -3.5861e-01, -1.6835e+00,  1.5682e+00,\n",
       "         -2.2886e+00,  2.1855e+00,  4.8974e+00, -6.5022e-01, -8.0860e-01,\n",
       "         -3.3333e+00,  3.3681e+00, -1.1730e+00,  1.1102e+00, -3.3873e+00,\n",
       "          4.7645e-02,  1.2891e+00,  3.0807e+00,  2.6720e+00, -1.0096e+00]],\n",
       "       grad_fn=<SumBackward2>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceLSTM(nn.Module):\n",
    "    def __init__(self, sentence_vec_size=200 ,hidden_size=100, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=sentence_vec_size, hidden_size=hidden_size, bidirectional=bidirectional, batch_first=True)\n",
    "    \n",
    "    def forward(self, input, hidden, cell):\n",
    "        o = self.lstm(input, (hidden, cell))\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_lstm = SentenceLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 200])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_vec.unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_0_s = torch.zeros(2,1,100)\n",
    "c_0_s = torch.zeros(2,1,100)\n",
    "sentence_output, (h_s, c_s) = sentence_lstm(s_vec.unsqueeze(dim=0), h_0_s, c_0_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 200])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentAttn(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.activation = nn.functional.tanh\n",
    "        self.sentence_context = nn.Parameter(torch.randn(hidden_size,1))\n",
    "    \n",
    "    def forward(self, sent_outputs):\n",
    "        \n",
    "        o = self.linear(sent_outputs)\n",
    "        o = self.activation(o)\n",
    "        o = torch.matmul(o, self.sentence_context)\n",
    "        o = torch.mul(o, sent_outputs)\n",
    "        o = torch.sum(o, dim=1) ## Sum along the sentences\n",
    "        \n",
    "        return o\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_attn = SentAttn(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shikhar/.conda/envs/ml/lib/python3.6/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "d_vec = s_attn(sentence_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputLayer(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.linear(input)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = OutputLayer(200)\n",
    "output = output_layer(d_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7345]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
